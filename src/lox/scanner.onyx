#load "./token"
#load "./lox"

use core { Map, printf, tprintf }
use core.conv
use core.list
use core.list { List }
use core.map

Scanner :: struct {
    source: str;
    tokens: List(Token) = list.make(Token);
    start: u32 = 0;
    current: u32 = 0;
    line: u32 = 1;

    scan_tokens :: (s: &Scanner) -> List(Token) {
        while !s->_is_at_end() {
            s.start = s.current;
            s->_scan_token();
        }

        list.push_end(&s.tokens, Token.{type=TokenType.EOF, lexeme="", line=s.line});
        return s.tokens;
    }

    _scan_token :: (s: &Scanner) => {
        c := s->_advance();
        switch c {
            case '(' {
                s->_add_token(TokenType.LEFT_PAREN);
            }
            case ')' {
                s->_add_token(TokenType.RIGHT_PAREN);
            }
            case '{' {
                s->_add_token(TokenType.LEFT_BRACE);
            }
            case '}' {
                s->_add_token(TokenType.RIGHT_BRACE);
            }
            case ',' {
                s->_add_token(TokenType.COMMA);
            }
            case '.' {
                s->_add_token(TokenType.DOT);
            }
            case '-' {
                s->_add_token(TokenType.MINUS);
            }
            case '+' {
                s->_add_token(TokenType.PLUS);
            }
            case ';' {
                s->_add_token(TokenType.SEMICOLON);
            }
            case '*' {
                s->_add_token(TokenType.STAR);
            }
            case '!' {
                s->_add_token(TokenType.BANG_EQUAL if s->_match('=') else TokenType.BANG);
            }
            case '=' {
                s->_add_token(TokenType.EQUAL_EQUAL if s->_match('=') else TokenType.EQUAL);
            }
            case '<' {
                s->_add_token(TokenType.LESS_EQUAL if s->_match('=') else TokenType.LESS);
            }
            case '>' {
                s->_add_token(TokenType.GREATER_EQUAL if s->_match('=') else TokenType.GREATER);
            }
            case '/' {
                if s->_match('/') {
                    // line comment
                    while s->_peek() != '\n' && !s->_is_at_end() {
                        s->_advance();
                    }
                } else {
                    s->_add_token(TokenType.SLASH);
                }
            }
            case '"' {
                s->_string();
            }
            // ignore spaces
            case ' ' {
            }
            case '\r' {
            }
            case '\t' {
            }
            case '\n' {
                s.line += 1;
            }
            case #default {
                if s->_is_digit(c) {
                    s->_number();
                } elseif s->_is_alpha(c) {
                    s->_identifier();
                } else {
                    Lox.error(s.line, tprintf("Unexpected character \"{}\".", c));
                }
            }
        }
    }

    _peek :: (s: &Scanner) -> u8 {
        if s->_is_at_end() {
            return '\0';
        }
        return s.source[s.current];
    }

    _peek_next :: (s: &Scanner) -> u8 {
        if s.current + 1 >= s.source.length {
            return '\0';
        }
        return s.source[s.current+1];
    }

    _match :: (s: &Scanner, expected: u8) -> bool {
        if s->_is_at_end() {
            return false;
        }
        if s.source[s.current] != expected {
            return false;
        }
        s.current += 1;
        return true;
    }

    _string :: (s: &Scanner) => {
        while s->_peek() != '"' && !s->_is_at_end() {
            if s->_peek() == '\n' {
                s.line += 1;
            }
            s->_advance();
        }

        if s->_is_at_end() {
            Lox.error(s.line, tprintf("Unterminated string."));
            return;
        }

        // consume end `"`
        s->_advance();

        value := s.source[s.start+1 .. s.current-1];
        s->_add_token(TokenType.STRING, TokenLiteral.{String=value});
    }

    _is_digit :: (s: &Scanner, c: u8) -> bool {
        return c >= '0' && c <= '9';
    }

    _number :: (s: &Scanner) {
        while s->_is_digit(s->_peek()) {
            s->_advance();
        }

        if s->_peek() == '.' && s->_is_digit(s->_peek_next()) {
            // consume `.`
            s->_advance();

            while s->_is_digit(s->_peek()) {
                s->_advance();
            }
        }

        value := conv.str_to_f64(s.source[s.start .. s.current]);
        s->_add_token(TokenType.NUMBER, TokenLiteral.{Number=value});
    }

    _is_alpha :: (s: &Scanner, c: u8) -> bool {
        return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || c == '_';
    }

    _is_alpha_numeric :: (s: &Scanner, c: u8) -> bool {
        return s->_is_alpha(c) || s->_is_digit(c);
    }

    _identifier :: (s: &Scanner) {
        while s->_is_alpha_numeric(s->_peek()) {
            s->_advance();
        }

        text := s.source[s.start .. s.current];
        keywords := s->_keywords();
        o := map.get(&keywords, text);
        switch o {
            case .None {
                s->_add_token(TokenType.IDENTIFIER);
                return;
            }
            case .Some as type {
                s->_add_token(type);
            }
        }
    }

    _is_at_end :: (s: &Scanner) -> bool {
        return s.current >= s.source.length;
    }

    _advance :: (s: &Scanner) -> u8 {
        current := s.current;
        s.current += 1;
        return s.source[current];
    }

    _keywords :: (s: &Scanner) -> Map(str, TokenType) {
        return Map.literal(str, TokenType, .[
            .{ "and", TokenType.AND },
            .{ "class", TokenType.CLASS },
            .{ "else", TokenType.ELSE },
            .{ "false", TokenType.FALSE },
            .{ "for", TokenType.FOR },
            .{ "fun", TokenType.FUN },
            .{ "if", TokenType.IF },
            .{ "nil", TokenType.NIL },
            .{ "or", TokenType.OR },
            .{ "print", TokenType.PRINT },
            .{ "return", TokenType.RETURN },
            .{ "super", TokenType.SUPER },
            .{ "this", TokenType.THIS },
            .{ "true", TokenType.TRUE },
            .{ "var", TokenType.VAR },
            .{ "while", TokenType.WHILE },
        ]);
    }

    _add_token :: #match {
        (s: &Scanner, type: TokenType) {
            return s->_add_token(type, TokenLiteral.{Null=.{}});
        },
        (s: &Scanner, type: TokenType, literal: TokenLiteral) {
            text := s.source[s.start..s.current];
            list.push_end(&s.tokens, Token.{type=type, lexeme=text, literal=literal, line=s.line});
        },
    }
}
